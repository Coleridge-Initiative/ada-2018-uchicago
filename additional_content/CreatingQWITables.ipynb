{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: center;\" src=\"images/CI_horizontal.png\" width=\"600\">\n",
    "<center>\n",
    "    <span style=\"font-size: 1.5em;\">\n",
    "        <a href='https://www.coleridgeinitiative.org'>Website</a>\n",
    "    </span>\n",
    "</center>\n",
    "\n",
    "Ghani, Rayid, Frauke Kreuter, Julia Lane, Adrianne Bradford, Alex Engler, Nicolas Guetta Jeanrenaud, Graham Henke, Daniela Hochfellner, Clayton Hunter, Brian Kim, Avishek Kumar, and Jonathan Morgan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applications: Replication QWI Statistics with MO Wage Records\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [Introduction](#Introduction)\n",
    "- [Basic Concepts](#Basic-Concepts)\n",
    "- [Python Setup](#Python-Setup)\n",
    "- [The Six Starter Files](#The-Six-Starter-Files)\n",
    "- [Longitudinal Linkage](#Longitudinal-Linkage)\n",
    "- [QWI Metrics](#QWI-Metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "This notebook presents an application of creating variables, as taught in the \"Variables\" notebook. Here we will generate the relevant metrics of the Quarterly Workforce Indicators (QWI) framework, for the overall Missouri economy and by business EIN. \n",
    "\n",
    "QWI is a robust method of quantifying the dynamic employment patterns of workers and firms. It was developed by the Longitudinal Employer-Household Dynamics (LEHD) program at the Census in collaboration with state employment security agencies across the US. LEHD collects administrative unemployment insurance (UI) and employer (Quarterly Census of Employment and Wages) data from the state agencies. It then standardizes and cleans the data, applies some statistical imputation procedures, calculates statistics, and finally makes aggregates available to the public and microdata available to researchers. This procedure is described in detail in \"The LEHD Infrastructure Files and the Creation of the Quarterly Workforce Indicators\" (Abowd et al. 2009. in \"Producer Dynamics: New Evidence from Micro Data\").\n",
    "\n",
    "In this notebook, we present code for turning simple Wage Records files into QWI files, as well as examples and suggestions for optimal use. \n",
    "\n",
    "> In the following steps, we will code the QWI metrics for a given quarter (2010 quarter 1). If you need these metrics for project work, the results for all quarters have been run and stored on the ADRF, in the `ada_18_uchi` schema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Concepts\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "The QWI framework is focused on **jobs**, which are the combination of **people** and **employers**. If John works at both McDonalds and Burger King, this will generate two completely separate jobs in the QWI data. If John quits his job at McDonalds, that job will no longer exist in the QWI data. If John quits both of his jobs, he will not be observed in the QWI data at all. The Wage Records files might contain \"jobs\" where no money changes hands in a given quarter. From the perspective of QWI, a job only exists if it involves wages greater than one dollar.\n",
    "\n",
    "In the ADRF environment, **People** are identified by their (hashed) Social Security Number and (hashed) name. In a perfect world, tracking people over time would simply be a matter of tracking their unique SSN. However, SSNs can be corrupted by data entry errors or used by multiple people. For the time being, we do not address these issues. We only longitudinally link two jobs if they have identical SSNs.\n",
    "\n",
    "Due to the fact that people who are unemployed or out of the labor force do not appear in QWI data, these data are not suitable for calculating population-wide employment rates of the kind produced by the Bureau of Labor Statistics. However, under the assumption that people who do not appear in the Wage Records data do not have jobs, QWI data can be used to calculate employment rates and other employment statistics for a subpopulation of people with known (hashed) SSNs. \n",
    "\n",
    "In this QWI routine, **Employers** are identified by their Employer Identification Number (EIN). Other methodologies use the Unemployment Insurance Account Number (UI Account Number).\n",
    "\n",
    "Each QWI file is specific to a single **quarter**. It includes a job if and only if it existed in that quarter. It includes information from prior and later quarters, but this is only to help construct the employment dynamics. The QWI file for 2010 quarter 2 gives a complete picture of the employment dynamics for that quarter but an incomplete (and likely misleading) picture of the employment dynamics for 2010 quarter 1 (or any other quarter). The Wage Records data tell us whether a job existed in a given quarter, but without more information we cannot differentiate a job that lasted the entire quarter from one that only lasted a day. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Setup\n",
    "- Back to [Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general use imports\n",
    "import datetime\n",
    "import glob\n",
    "import inspect\n",
    "import numpy\n",
    "import os\n",
    "import six\n",
    "import warnings\n",
    "import math\n",
    "from itertools import izip\n",
    "\n",
    "# pandas-related imports\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "\n",
    "# CSV file reading-related imports\n",
    "import csv\n",
    "\n",
    "# database interaction imports\n",
    "import sqlalchemy\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# to create a connection to the database, we need to pass the name of the database and host of the database\n",
    "connection_string = \"postgresql://10.10.2.10/appliedda\"\n",
    "conn = sqlalchemy.create_engine(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## makeDataDict: A function to split a dataset into 6 quarterly datasets for use in QWI calculations\n",
    "## Inputs: \n",
    "## -connection: Connection to the database\n",
    "## -keyYr: The year to caculate QWI stats for\n",
    "## -keyQ: The quarter to calculate QWI stats for\n",
    "## Output:\n",
    "## -res: A dictionary with keys m4, m3, m2, m1, t, and p1 containing subsets of the longDat that condition\n",
    "## on keyRy/keyQ (for entry 't'), 4 lags ('m1'-'m4'), and one lead ('p1')\n",
    "def makeDataDict(connection, keyYr, keyQ):\n",
    "    keys = ['m4', 'm3', 'm2', 'm1', 't', 'p1']\n",
    "    res = {}\n",
    "    for i in range(0,6):\n",
    "        ##Find the right year and quarter, with i=0 corresponding to the 4th lag   \n",
    "        yr = int(keyYr - 1 + math.floor((keyQ+i-1)/4))\n",
    "        q = int(keyQ + i - 4*math.floor((keyQ+i-1)/4))\n",
    "        \n",
    "        # Query the dataset on the given year and quarter, keeping only identifiers and wage as columns \n",
    "        query='''\n",
    "        SELECT ssn\n",
    "                , ein\n",
    "                , 1 as wage \n",
    "        FROM il_des_kcmo.il_wage\n",
    "        WHERE year = {} and quarter = {}\n",
    "        '''.format(yr, q)\n",
    "        \n",
    "        res[keys[i]] = pd.read_sql(query, connection)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## linkData: A function to longitudinally link the datasets supplied in the form of a dictionary output by \n",
    "## makedataDict. Currently links by a deterministic left merge (where 't' is always on the left) by SSN and EIN.\n",
    "## Input:\n",
    "## -dataDict: A dictionary with keys m4, m3, m2, m1, t, and p1 containing subsets of the longDat that condition\n",
    "## on keyRy/keyQ (for entry 't'), 4 lags ('m1'-'m4'), and one lead ('p1')\n",
    "## Output: \n",
    "## -res: A single dataframe with columns SSN, EIN, and wage_m4-wage_p1, the results of the \n",
    "## longitudinal linkage. A job is included iff it exists in period 't'. When that job does not exist in a different\n",
    "## period, the record describing that job will have  a missing value in the column for that period. \n",
    "def linkData(dataDict):\n",
    "    for time in dataDict:\n",
    "        dataDict[time] = dataDict[time][(dataDict[time]['wage'].notnull())]\n",
    "    res = dataDict['t']\n",
    "    for time in dataDict:\n",
    "        if time != 't':\n",
    "            ##Define the suffix to add to the time period being merged in \n",
    "            suff = '_' + time\n",
    "            ##Merge on iddssn, uiacctno. Keep all records in 't'. Drop unmatched records in the other period. \n",
    "            res = pd.merge(left=res, right=dataDict[time], on=['ssn','ein'], how='left', suffixes=('',suff))\n",
    "    res = res[['ssn', 'ein', 'wage', 'wage_m4', 'wage_m3', 'wage_m2', 'wage_m1', 'wage_p1']]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## makeStatistics: A function to calculate QWI statistics \n",
    "## (employment-stable employment, accessions and separations therefrom, etc.). \n",
    "## Input:\n",
    "## -linkData: A single dataframe with columns idssn, uiacctno, and wage_m4-wage_p1. \n",
    "## Missing entries will be interpreted as the non-existence of a job.\n",
    "## Output:\n",
    "## -res: The input dataset with columns appended for each statistic.\n",
    "\n",
    "def makeStatistics(linkData):\n",
    "    res = linkData\n",
    "    \n",
    "    #Flow Employment\n",
    "    res['qwmt'] = 1*(res['wage'] > 0)\n",
    "    res['qwmtm4'] = 1*(res['wage_m4'] > 0)\n",
    "    res['qwmtm3'] = 1*(res['wage_m3'] > 0)\n",
    "    res['qwmtm2'] = 1*(res['wage_m2'] > 0)\n",
    "    res['qwmtm1'] = 1*(res['wage_m1'] > 0)\n",
    "    res['qwmtp1'] = 1*(res['wage_p1'] > 0)\n",
    "            \n",
    "    #Beginning of Quarter Employment\n",
    "    res['qwbt'] = 1*((res['qwmtm1']==1) & (res['qwmt']==1))\n",
    "\n",
    "    #End of Quarter Employment\n",
    "    res['qwet'] = 1*((res['qwmt']==1) & (res['qwmtp1']==1))\n",
    "\n",
    "    #Full Quarter Employment\n",
    "    res['qwft'] = 1*((res['qwmtm1']==1) & (res['qwmt']==1) & (res['qwmtp1']==1))\n",
    "\n",
    "    #Accessions\n",
    "    res['qwat'] = 1*((res['qwmtm1']==0) & (res['qwmt']==1))\n",
    "    \n",
    "    #Accessions to Consecutive Quarter Status\n",
    "    res['qwa2t'] = 1*((res['qwat']==1) & (res['qwmtp1']==1))\n",
    "\n",
    "    #Accessions to Full Quarter Status\n",
    "    res['qwa3t'] = 1*((res['qwmtm2']==0) & (res['qwmtm1']==1) & (res['qwmt']==1) \n",
    "                      & (res['qwmtp1']==1))\n",
    "\n",
    "    #Separations\n",
    "    res['qwst'] = 1*((res['qwmt']==1) & (res['qwmtp1']==0))\n",
    "    \n",
    "    #New Hires\n",
    "    res['qwht'] = 1*((res['qwmtm4']==0) & (res['qwmtm3']==0) & (res['qwmtm2']==0) \n",
    "                     & (res['qwmtm1']==0) & (res['qwmt']==1))\n",
    "\n",
    "    #Recalls\n",
    "    res['qwrt'] = 1*((res['qwmtm1']==0) & (res['qwmt']==1) & (res['qwht']==0))\n",
    "\n",
    "    \n",
    "    ##Replace technical names by more explicit names\n",
    "    names_tech = (['qwmt','qwmtm4','qwmtm3','qwmtm2','qwmtm1','qwmtp1','qwbt'\n",
    "                   ,'qwet','qwft','qwat','qwa2t','qwa3t','qwst','qwht','qwrt'])\n",
    "    names_def =(['emp_current_qrt','emp_4qtrs_ago','emp_3qtrs_ago','emp_2qtrs_ago'\n",
    "                 ,'emp_prev_qtr', 'emp_next_qtr','emp_begin_qtr','emp_end_qtr'\n",
    "                 ,'emp_full_qtr','accessions_current', 'accessions_consecutive_qtr'\n",
    "                 ,'accessions_full_qtr','separations','new_hires','recalls'])\n",
    "    rn_dict = dict(izip(names_tech, names_def))\n",
    "    res = res.rename(index=str, columns=rn_dict)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qwi_vars =(['emp_current_qrt','emp_4qtrs_ago','emp_3qtrs_ago','emp_2qtrs_ago','emp_prev_qtr'\n",
    "             , 'emp_next_qtr','emp_begin_qtr','emp_end_qtr','emp_full_qtr','accessions_current'\n",
    "             , 'accessions_consecutive_qtr','accessions_full_qtr','separations','new_hires','recalls'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2012,2016):\n",
    "    full_data = makeDataDict(conn, i, 1)\n",
    "    print(\"Downloaded \" + str(i) + \" data\")\n",
    "    \n",
    "    linked_data = linkData(full_data)\n",
    "    print(\"Linked \"+ str(i) + \" data\")\n",
    "    \n",
    "    qwi_stats = makeStatistics(linked_data)\n",
    "    qwi_ein_stats = qwi_stats.groupby(['ein'])[qwi_vars].mean().reset_index()\n",
    "    qwi_ein_count = qwi_stats.groupby(['ein']).size().reset_index()\n",
    "    qwi_ein_count['nb_empl'] = qwi_ein_count[0]\n",
    "    del qwi_ein_count[0]\n",
    "    qwi_ein = pd.merge(qwi_ein_count, qwi_ein_stats, on = 'ein')\n",
    "    \n",
    "    table_name = 'qwi_ein_' + str(i) + \"_1\"\n",
    "    \n",
    "    conn = sqlalchemy.create_engine(connection_string)\n",
    "    qwi_ein.to_sql(table_name, conn, schema = 'ada_18_uchi')\n",
    "    print(\"Uploaded \" + str(i) + \" data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "1072px",
    "left": "324px",
    "top": "193.958px",
    "width": "338px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
