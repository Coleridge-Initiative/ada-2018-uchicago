{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pdf\n",
    "import datetime\n",
    "import sqlalchemy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQLAlchemy connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database connection properties\n",
    "db_host = \"10.10.2.10\"\n",
    "db_port = -1\n",
    "db_username = None\n",
    "db_password = None\n",
    "db_name = \"appliedda\"\n",
    "\n",
    "print( \"Database connection properties initialized at \" + str( datetime.datetime.now() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize database connections\n",
    "# Create connection to database using SQLAlchemy\n",
    "#     (3 '/' indicates use enviroment settings for username, host, and port)\n",
    "sqlalchemy_connection_string = \"postgresql://\"\n",
    "\n",
    "if ( ( db_host is not None ) and ( db_host != \"\" ) ):\n",
    "    sqlalchemy_connection_string += str( db_host )\n",
    "#-- END check to see if host --#\n",
    "\n",
    "sqlalchemy_connection_string += \"/\"\n",
    "\n",
    "if ( ( db_name is not None ) and ( db_name != \"\" ) ):\n",
    "    sqlalchemy_connection_string += str( db_name )\n",
    "#-- END check to see if host --#\n",
    "\n",
    "# create engine.\n",
    "pgsql_engine = sqlalchemy.create_engine( sqlalchemy_connection_string )\n",
    "\n",
    "print( \"SQLAlchemy engine created at \" + str( datetime.datetime.now() ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load csv into pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath = \"put the full path of your csv file here\"\n",
    "\n",
    "df = pd.read_csv(filepath)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save dataframe to your schema in SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# work schema name - name of your group's schema\n",
    "work_schema_name = \"ada_class3\"\n",
    "\n",
    "# admin role\n",
    "admin_role = work_schema_name + \"_admin\"\n",
    "select_role = work_schema_name + \"_select\"\n",
    "\n",
    "# ==> database table names - just like file names above, store reused database information in variables here.\n",
    "\n",
    "# work table name - name you want your table to be in SQL\n",
    "work_db_table = \"hh_member_work\"\n",
    "\n",
    "print( \"Database variables initialized at \" + str( datetime.datetime.now() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_sql(work_db_table, pgsql_engine, schema=work_schema_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set permissions so your other group members can work with table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create psycopg2 connection to Postgresql\n",
    "\n",
    "# example connect() call that uses all the possible parameters\n",
    "#pgsql_connection = psycopg2.connect( host = db_host, port = db_port, database = db_name, user = db_username, password = db_password )\n",
    "\n",
    "# for SQLAlchemy, just needed database name. Same for DBAPI?\n",
    "pgsql_connection = psycopg2.connect( host = db_host, database = db_name )\n",
    "\n",
    "print( \"Postgresql connection to database \\\"\" + db_name + \"\\\" created at \" + str( datetime.datetime.now() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a cursor that maps column names to values\n",
    "pgsql_cursor = pgsql_connection.cursor( cursor_factory = psycopg2.extras.DictCursor )\n",
    "\n",
    "print( \"Postgresql cursor for database \\\"\" + db_name + \"\\\" created at \" + str( datetime.datetime.now() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate SQL\n",
    "sql_string = \"ALTER TABLE \" + work_schema_name + \".\" + work_db_table\n",
    "sql_string += \" OWNER TO \" + admin_role\n",
    "sql_string += \";\"\n",
    "\n",
    "# run SQL\n",
    "pgsql_cursor.execute( sql_string )\n",
    "pgsql_connection.commit()\n",
    "\n",
    "#temp_df = pandas.read_sql( sql_string, con = pgsql_engine )\n",
    "#temp_length = len( temp_df )\n",
    "#temp_df.head( n = temp_length )\n",
    "\n",
    "print( \"====> \" + str( sql_string ) + \" completed at \" + str( datetime.datetime.now() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate SQL\n",
    "sql_string = \"GRANT ALL PRIVILEGES ON TABLE \" + work_schema_name + \".\" + work_db_table\n",
    "sql_string += \" TO \" + admin_role\n",
    "sql_string += \";\"\n",
    "\n",
    "# run SQL\n",
    "pgsql_cursor.execute( sql_string )\n",
    "pgsql_connection.commit()\n",
    "\n",
    "#temp_df = pandas.read_sql( sql_string, con = pgsql_engine )\n",
    "#temp_length = len( temp_df )\n",
    "#temp_df.head( n = temp_length )\n",
    "\n",
    "print( \"====> \" + str( sql_string ) + \" completed at \" + str( datetime.datetime.now() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate SQL\n",
    "sql_string = \"GRANT SELECT ON TABLE \" + work_schema_name + \".\" + work_db_table\n",
    "sql_string += \" TO \" + select_role\n",
    "sql_string += \";\"\n",
    "\n",
    "# run SQL\n",
    "pgsql_cursor.execute( sql_string )\n",
    "pgsql_connection.commit()\n",
    "\n",
    "#temp_df = pandas.read_sql( sql_string, con = pgsql_engine )\n",
    "#temp_length = len( temp_df )\n",
    "#temp_df.head( n = temp_length )\n",
    "\n",
    "print( \"====> \" + str( sql_string ) + \" completed at \" + str( datetime.datetime.now() ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
