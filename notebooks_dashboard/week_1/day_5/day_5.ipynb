{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Illinois Dashboard - Day 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Description\n",
    "\n",
    "During the first modules, due to the large size of the overall Wage Data, you restricted all plots to a random sample of the data. In this notebook, you will incorporate the entire data without increasing the run time: by collapsing the underlying data into wage, county, year and quarter buckets. The steps will be the following:\n",
    "- Write a SQL Query that buckets the underlying data\n",
    "- Alter dashboard queries so they pull from the bucketed data\n",
    "- Run dashboard on entire data and observe run time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package for database connection\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Packages for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "\n",
    "# Packages for visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Ignore warnings. This is to prevent distracting notices of new packages that are unnecessary\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database connection\n",
    "engine = create_engine('postgresql://@10.10.2.10/appliedda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by taking a look at the data we have at our disposal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dashboard Data (random sample)\n",
    "query = '''\n",
    "SELECT *\n",
    "FROM ada_18_uchi.dashboard_data_il_jobs_rs\n",
    "LIMIT 5;\n",
    "'''\n",
    "df = pd.read_sql(query, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data the dashboard currently pulls from is still microdata: every observation accounts for a single individual. The dashboard however displays county-level metrics. Pulling from millions of individual-level observations significantly increases the run-time, as we saw in the first module. Would there be a way to reduce the underlying data and increase the run time? **Discuss potential solutions with your team.**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way of reducing the underlying data is grouping already by year, quarter, and county. In this case, the dashboard query will simply pull the metrics for every county at the given year and quarter. Here is how we would modify the underlying data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT cnty, year, qtr,\n",
    "    count(*) as jobs, \n",
    "    avg(wage) as avg_wage\n",
    "from ada_18_uchi.dashboard_data_il_jobs_rs\n",
    "group by cnty, year, qtr\n",
    "order by cnty, year, qtr\n",
    "'''\n",
    "df_grouped = pd.read_sql(query, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is great if you are looking at the metrics on the overall population. But the dashboard let's you restrict to subgroups of interest (by minimum and maximum earnings, for example), and this feature is lost when pulling from the above table. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of entirely grouping the data by county, let's keep different earning buckets so we can still filter the dashboard visualization to subgroups of interest. For example, let's group the data by buckets of \\$1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT cnty, year, qtr,\n",
    "    (wage/1000)*1000 as wage_bucket,\n",
    "    count(*) as jobs, \n",
    "    avg(wage) as avg_wage\n",
    "from ada_18_uchi.dashboard_data_il_jobs_rs\n",
    "group by year, qtr, cnty, (wage/1000)*1000\n",
    "order by year, qtr, cnty, (wage/1000)*1000;\n",
    "'''\n",
    "df_grouped = pd.read_sql(query, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The underlying data is now much more reduced than microdata, but still has the flexibility of subsetting to earning groups of interest. This should be perfect for our dashboard!\n",
    "\n",
    "The entire data has been grouped in this way and saved as the table `ada_18_uchi.dashboard_data_il_buckets`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incorporating in Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have created this flag, let's add this flag to the previous `group by` query that we used to generate the dashboard. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_qry = \"\"\"\n",
    "select cnty, \n",
    "    sum(jobs) as jobs, \n",
    "    sum(jobs*avg_wage)/sum(jobs) as avg_wage\n",
    "from ada_18_uchi.dashboard_data_il_buckets\n",
    "where year = {y} and qtr = {q}\n",
    "group by cnty\n",
    "order by cnty\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_qry = '''\n",
    "select a.cnty,\n",
    "    cast(b.jobs - a.jobs as decimal)/(a.jobs+1) as change_in_jobs_pct,\n",
    "    cast(b.avg_wage - a.avg_wage as decimal)/(a.avg_wage+1) as change_in_avg_wage_pct\n",
    "from(\n",
    "    select cnty, \n",
    "        sum(jobs) as jobs, \n",
    "        sum(jobs*avg_wage)/sum(jobs) as avg_wage\n",
    "    from ada_18_uchi.dashboard_data_il_buckets\n",
    "    where year = {y0} and qtr = {q0} \n",
    "    group by cnty\n",
    ") as a\n",
    "full join (\n",
    "    select cnty, \n",
    "        sum(jobs) as jobs, \n",
    "        sum(jobs*avg_wage)/sum(jobs) as avg_wage\n",
    "    from ada_18_uchi.dashboard_data_il_buckets\n",
    "    where year = {y1} and qtr = {q1}\n",
    "    group by cnty\n",
    ") as b\n",
    "on a.cnty = b.cnty\n",
    "order by cnty\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dashboard Functions\n",
    "from ui import DashUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics to plot\n",
    "statefp = '17' # 17 is statefp for Illinois\n",
    "list_of_metrics = {'Jobs': 'jobs'\n",
    "                   , 'Average Quarterly Earnings': 'avg_wage'\n",
    "                   \n",
    "                   # Insert additional metric for New Jobs\n",
    "                   \n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dashboard\n",
    "dash = DashUI(statefp, list_of_metrics, count_qry, change_qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Display the input panel and the output of the dashboard\n",
    "display(dash.input_panel)\n",
    "display(dash.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py2-dashboard",
   "language": "python",
   "name": "py2-dashboard"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
